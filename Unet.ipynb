{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_dEvW-fAD72",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7db151e0-f3a9-4db2-d35e-567ba4613936"
      },
      "source": [
        "import cv2\n",
        "import PIL\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import keras\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras import Input, Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from matplotlib import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Lambda\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras.layers.convolutional import Deconvolution2D, Conv2DTranspose, Conv2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras import backend\n",
        "\n",
        "def cnn_model():\n",
        "    # Channels first tells the pooling layer to use the (Height, Width, Depth) format instead of the (Depth, Height, Width)\n",
        "    data_format=\"channels_first\"\n",
        "    model = Sequential()\n",
        "    model.add(Convolution2D(32, (3, 3), input_shape=(150, 150, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(data_format=data_format, pool_size=(2, 2)))\n",
        "    model.add(Convolution2D(32, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(data_format=data_format, pool_size=(2, 2)))\n",
        "    model.add(Convolution2D(64, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(data_format=data_format, pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1))\n",
        "    model.add(Activation('sigmoid'))\n",
        "    model.compile(optimizer='rmsprop',              # Performs gradient descent, finding the lowest error value\n",
        "                  loss='binary_crossentropy',       # Cross entropy measures the performance of each prediction made by the network\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def create_model():\n",
        "    # Channels first tells the pooling layer to use the (Height, Width, Depth) format instead of the (Depth, Height, Width)\n",
        "    data_format=\"channels_first\"\n",
        "    # A sequential model is a basic model structure where the layers are stacked layer by layer.\n",
        "    # Another option with keras is a functional model, layers can be connected to literally any other layer within the model.\n",
        "    model = Sequential()\n",
        "    # A convolutional layer slides a filter over the image which is fed to the activation layer so the model can learn\n",
        "    # features and activate when they see one of these visual features. Only activated features are carried over to the\n",
        "    # next layer.\n",
        "    model.add(Conv2D(32, (3, 3), input_shape=(256, 256, 3),))\n",
        "    # Relu maps all negative values to 0 and keeps all positive values.\n",
        "    model.add(Activation('relu'))\n",
        "    # A pooling layer reduces the dimensions of the image but not the depth. The computation is faster and less image data\n",
        "    # means less chance of over fitting.\n",
        "    model.add(MaxPooling2D(data_format=data_format, pool_size=(2, 2)))\n",
        "    model.add(Conv2D(32, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(data_format=data_format, pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(data_format=data_format, pool_size=(2, 2)))\n",
        "    model.add(Conv2DTranspose(1, (3, 3), output_shape=(256,256)))\n",
        "    model.compile(optimizer='rmsprop',              # Performs gradient descent, finding the lowest error value\n",
        "                  loss='binary_crossentropy',       # Cross entropy measures the performance of each prediction made by the network\n",
        "                  metrics=['accuracy'])\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "def mean_iou(y_true, y_pred):\n",
        "    prec = []\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        y_pred_ = tf.to_int32(y_pred > t)\n",
        "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
        "        backend.get_session().run(tf.local_variables_initializer())\n",
        "        with tf.control_dependencies([up_opt]):\n",
        "            score = tf.identity(score)\n",
        "        prec.append(score)\n",
        "    return backend.mean(backend.stack(prec), axis=0)\n",
        "\n",
        "\n",
        "def unet_model():\n",
        "    inputs = Input((256,256,3))\n",
        "    s = Lambda(lambda x: x / 255)(inputs)\n",
        "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(s)\n",
        "    c1 = Dropout(0.1)(c1)\n",
        "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "    c2 = Dropout(0.1)(c2)\n",
        "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "    c3 = Dropout(0.2)(c3)\n",
        "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "    c4 = Dropout(0.2)(c4)\n",
        "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
        "\n",
        "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "    c5 = Dropout(0.3)(c5)\n",
        "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "\n",
        "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = Dropout(0.2)(c6)\n",
        "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "\n",
        "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = Dropout(0.2)(c7)\n",
        "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "\n",
        "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "    c8 = Dropout(0.1)(c8)\n",
        "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "\n",
        "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = concatenate([u9, c1], axis=3)\n",
        "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "    c9 = Dropout(0.1)(c9)\n",
        "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "model = unet_model()\n",
        "batch_size = 16\n",
        "train_size = 2000\n",
        "test_size = 500\n",
        "train = []\n",
        "truth = []\n",
        "path = 'data/train/'\n",
        "for file in os.listdir(path):\n",
        "    img = image.imread(path+file)\n",
        "    train.append(img/255)\n",
        "print(str(len(train))+ \" images loaded for training\")\n",
        "print(np.asarray(train).shape)\n",
        "path = 'data/train_truth/'\n",
        "for file in os.listdir(path):\n",
        "    img = image.imread(path+file)\n",
        "    truth.append(img/255)\n",
        "print(str(len(truth))+ \" Truth images loaded for training\")\n",
        "print(np.asarray(truth).shape)\n",
        "x, y = zip(*random.sample(list(zip(train, truth)), train_size+test_size))\n",
        "x_train = np.asarray(x[:train_size])\n",
        "#x_train = x_train.reshape((1,)+ x_train.shape)\n",
        "x_test = np.asarray(x[train_size:])\n",
        "y_train = np.asarray(y[:train_size])\n",
        "y_train = y_train.reshape(y_train.shape + (1,))\n",
        "y_test = np.asarray(y[train_size:])\n",
        "y_test = y_test.reshape(y_test.shape + (1,))\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "callbacks = [EarlyStopping(patience=10, verbose=1)]\n",
        "#model = create_model()\n",
        "model.fit(x=x_train,y=y_train,batch_size=batch_size,epochs=5,validation_data=(x_test,y_test),callbacks = callbacks)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'FCN_Test'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n",
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}